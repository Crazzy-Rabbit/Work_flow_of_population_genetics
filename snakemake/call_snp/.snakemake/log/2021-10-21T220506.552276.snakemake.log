Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 15
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job              count    min threads    max threads
-------------  -------  -------------  -------------
all                  1              1              1
combine_gvcf         1              1              1
indel_filter         1              1              1
indel_select         1              1              1
joint_calling        1              1              1
snp_filter           1              1              1
snp_select           1              1              1
total                7              1              1

Select jobs to execute...

[Thu Oct 21 22:05:07 2021]
rule combine_gvcf:
    input: gvcf/SRR15006267.g.vcf.gz, gvcf/SRR15006269.g.vcf.gz, reference/ref.fasta
    output: combined.g.vcf.gz
    jobid: 9
    resources: tmpdir=/tmp

[Thu Oct 21 22:05:07 2021]
Error in rule combine_gvcf:
    jobid: 9
    output: combined.g.vcf.gz
    shell:
        
        gatk CombineGVCFs --java-options "-Xms512m -Xmx4g" -R reference/ref.fasta $(echo gvcf/SRR15006267.g.vcf.gz gvcf/SRR15006269.g.vcf.gz | sed 's/gvcf/ --variant gvcf/g') -O combined.g.vcf.gz"
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /data/00/user/user186/Work_flow_of_population_genetics/snakemake/call_snp/.snakemake/log/2021-10-21T220506.552276.snakemake.log
